{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkFC5DYO9QqwTF7ZaxDyDE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#IMPORTING THE LIBRARIES"],"metadata":{"id":"QACZ9ArxSlcw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QqlsxggHRqb9"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf"]},{"cell_type":"markdown","source":["#IMPORTING THE DATASET"],"metadata":{"id":"eO81jPlVSrIG"}},{"cell_type":"code","source":["dataset = pd.read_csv('Churn_Modelling.csv')\n","X = dataset.iloc[:, 3:-1].values #columns 0,1,2 index does not provide any impact for the model. so we start from 3rd column and exclude the last column\n","y = dataset.iloc[:, -1].values"],"metadata":{"id":"ziEuoEPxStNv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tHBIbCXYxrGV","executionInfo":{"status":"ok","timestamp":1687774852538,"user_tz":-330,"elapsed":27,"user":{"displayName":"Simandhar Kumar Baid","userId":"16150880934178117180"}},"outputId":"ef401c74-a171-42b2-84ca-fbd5da55b4dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[619 'France' 'Female' ... 1 1 101348.88]\n"," [608 'Spain' 'Female' ... 0 1 112542.58]\n"," [502 'France' 'Female' ... 1 0 113931.57]\n"," ...\n"," [709 'France' 'Female' ... 0 1 42085.58]\n"," [772 'Germany' 'Male' ... 1 0 92888.52]\n"," [792 'France' 'Female' ... 1 0 38190.78]]\n"]}]},{"cell_type":"code","source":["print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-ZLJwCqxuD8","executionInfo":{"status":"ok","timestamp":1687774852539,"user_tz":-330,"elapsed":25,"user":{"displayName":"Simandhar Kumar Baid","userId":"16150880934178117180"}},"outputId":"a90ec304-f5a8-402e-af6a-bfcf11a195f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 1 ... 1 1 0]\n"]}]},{"cell_type":"markdown","source":["#Encoding the categorical data"],"metadata":{"id":"nUs27LyXxzhj"}},{"cell_type":"code","source":["#Here there are 2 categorical data, gender and the country"],"metadata":{"id":"7A3-DMfOx2FG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Label encoding the gender column"],"metadata":{"id":"7IUFosbqyDde"}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","X[:, 2] = le.fit_transform(X[:, 2]) #it means all rows of the column index 2"],"metadata":{"id":"1ejS_I6NyG9W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4MfIJKGpypAp","executionInfo":{"status":"ok","timestamp":1687774852540,"user_tz":-330,"elapsed":21,"user":{"displayName":"Simandhar Kumar Baid","userId":"16150880934178117180"}},"outputId":"aaa5a158-0532-412e-b070-70117a43b707"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[619 'France' 0 ... 1 1 101348.88]\n"," [608 'Spain' 0 ... 0 1 112542.58]\n"," [502 'France' 0 ... 1 0 113931.57]\n"," ...\n"," [709 'France' 0 ... 0 1 42085.58]\n"," [772 'Germany' 1 ... 1 0 92888.52]\n"," [792 'France' 0 ... 1 0 38190.78]]\n"]}]},{"cell_type":"markdown","source":["#One hot encoding the country column (because it contains more than 2 countries so we cannot use label encoder with just 0 and 1)"],"metadata":{"id":"HlCzh7hJyrQo"}},{"cell_type":"code","source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n","X = np.array(ct.fit_transform(X))"],"metadata":{"id":"27dyoXvmyvZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7QSlAMoCy0vJ","executionInfo":{"status":"ok","timestamp":1687774852540,"user_tz":-330,"elapsed":17,"user":{"displayName":"Simandhar Kumar Baid","userId":"16150880934178117180"}},"outputId":"5b2a1b6c-4db1-4e85-98ec-8c136a86433f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0 0.0 0.0 ... 1 1 101348.88]\n"," [0.0 0.0 1.0 ... 0 1 112542.58]\n"," [1.0 0.0 0.0 ... 1 0 113931.57]\n"," ...\n"," [1.0 0.0 0.0 ... 0 1 42085.58]\n"," [0.0 1.0 0.0 ... 1 0 92888.52]\n"," [1.0 0.0 0.0 ... 1 0 38190.78]]\n"]}]},{"cell_type":"markdown","source":["#Splitting dataset into train and test cell"],"metadata":{"id":"SLzBl2Y63z0G"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"],"metadata":{"id":"oza9W9pO31yN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Feature scalling\n","***Whenever u apply neural network, u have to apply feature scalling.Have to scale every feature in the dataset and it is important for neural network***"],"metadata":{"id":"fB9cuD9czuR3"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"],"metadata":{"id":"std1Qfmg0OJx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Part 2-Build the ANN"],"metadata":{"id":"u7LYWKOaafaD"}},{"cell_type":"markdown","source":["Initializing the ANN"],"metadata":{"id":"ILUk2_cj1BWV"}},{"cell_type":"code","source":["ann=tf.keras.models.Sequential()"],"metadata":{"id":"L6vL2cQMz3fz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Adding the input layer and the first hidden layer"],"metadata":{"id":"Cr8Xxqxg4VyC"}},{"cell_type":"code","source":["ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"],"metadata":{"id":"IZUqaxAPajAj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Adding the second hidden layer"],"metadata":{"id":"NFXfNk6t5OOb"}},{"cell_type":"code","source":["ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"],"metadata":{"id":"f8o61HXJmIsb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Adding the ouput layer"],"metadata":{"id":"UtNgv1uE6UCV"}},{"cell_type":"code","source":["ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n","#sigmoid functions helps in providing predictions as well as probablities so it is recommended that the output layer uses a sigmoid function\n","#use activation softmax for output layer if there is more than 2 features to represent for classfication\n","#for regression, no activation function in the output layer"],"metadata":{"id":"9SKoZXDn6V94"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Training the ANN"],"metadata":{"id":"DUno5YdWmltn"}},{"cell_type":"markdown","source":["Compiling the ANN"],"metadata":{"id":"awU5dFOg6-03"}},{"cell_type":"code","source":["ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n","#optimizer updates the weight through stochastic gradient descent\n","#loss to compute difference between predictions and real\n","#metrics for accuracy\n","#binary_crossentropy for binary classfication and categorical_crossentropy for non binary classfication\n","#for non binary , the activation should be softmax in the output layer"],"metadata":{"id":"BW8JvF6SnRzD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training the ANN on the training set"],"metadata":{"id":"_oU3B83lmpgq"}},{"cell_type":"code","source":["ann.fit(X_train, y_train, batch_size = 32, epochs = 100)\n","#batch size refers to number of predictions vs  the real results\n","#epochs refer to number of times the neural network is trained"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1_SGAJ2nY9K","executionInfo":{"status":"ok","timestamp":1687774884171,"user_tz":-330,"elapsed":31642,"user":{"displayName":"Simandhar Kumar Baid","userId":"16150880934178117180"}},"outputId":"4e5a4715-8cb4-4eee-ba40-fb90ae287ae0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","250/250 [==============================] - 1s 1ms/step - loss: 0.5537 - accuracy: 0.7445\n","Epoch 2/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7961\n","Epoch 3/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7976\n","Epoch 4/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.8043\n","Epoch 5/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8123\n","Epoch 6/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4031 - accuracy: 0.8145\n","Epoch 7/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3921 - accuracy: 0.8175\n","Epoch 8/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3827 - accuracy: 0.8195\n","Epoch 9/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8216\n","Epoch 10/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8394\n","Epoch 11/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8453\n","Epoch 12/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8505\n","Epoch 13/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8549\n","Epoch 14/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.8576\n","Epoch 15/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8584\n","Epoch 16/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.8583\n","Epoch 17/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8596\n","Epoch 18/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3449 - accuracy: 0.8585\n","Epoch 19/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3434 - accuracy: 0.8597\n","Epoch 20/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8589\n","Epoch 21/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8595\n","Epoch 22/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8589\n","Epoch 23/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8594\n","Epoch 24/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8584\n","Epoch 25/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8609\n","Epoch 26/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8600\n","Epoch 27/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8595\n","Epoch 28/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8597\n","Epoch 29/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8594\n","Epoch 30/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8608\n","Epoch 31/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8601\n","Epoch 32/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8608\n","Epoch 33/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8614\n","Epoch 34/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8606\n","Epoch 35/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8602\n","Epoch 36/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8612\n","Epoch 37/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8612\n","Epoch 38/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8621\n","Epoch 39/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8610\n","Epoch 40/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8625\n","Epoch 41/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8630\n","Epoch 42/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8612\n","Epoch 43/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8610\n","Epoch 44/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8618\n","Epoch 45/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8597\n","Epoch 46/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8620\n","Epoch 47/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8600\n","Epoch 48/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8624\n","Epoch 49/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8616\n","Epoch 50/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8619\n","Epoch 51/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8619\n","Epoch 52/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8625\n","Epoch 53/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8609\n","Epoch 54/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8621\n","Epoch 55/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8622\n","Epoch 56/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8621\n","Epoch 57/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8631\n","Epoch 58/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8625\n","Epoch 59/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8619\n","Epoch 60/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8604\n","Epoch 61/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8621\n","Epoch 62/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8624\n","Epoch 63/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8616\n","Epoch 64/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8616\n","Epoch 65/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8620\n","Epoch 66/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8620\n","Epoch 67/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8609\n","Epoch 68/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8625\n","Epoch 69/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8631\n","Epoch 70/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8619\n","Epoch 71/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8618\n","Epoch 72/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8633\n","Epoch 73/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8627\n","Epoch 74/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8625\n","Epoch 75/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8633\n","Epoch 76/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8631\n","Epoch 77/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8633\n","Epoch 78/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8630\n","Epoch 79/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8625\n","Epoch 80/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8620\n","Epoch 81/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8618\n","Epoch 82/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8622\n","Epoch 83/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8629\n","Epoch 84/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8629\n","Epoch 85/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8615\n","Epoch 86/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8624\n","Epoch 87/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8624\n","Epoch 88/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8639\n","Epoch 89/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8625\n","Epoch 90/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8620\n","Epoch 91/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8626\n","Epoch 92/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8630\n","Epoch 93/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8619\n","Epoch 94/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8625\n","Epoch 95/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8626\n","Epoch 96/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8625\n","Epoch 97/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8620\n","Epoch 98/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8629\n","Epoch 99/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8615\n","Epoch 100/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8634\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f88abe32ef0>"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["#Making the predictions and evaluating the model"],"metadata":{"id":"n2qUo0prmuAH"}},{"cell_type":"markdown","source":["Predicting the result of a single observation"],"metadata":{"id":"9cGGpMyyOn18"}},{"cell_type":"code","source":["print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5) #0.5 is threshold for prediction"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BmKJPt_Fne61","executionInfo":{"status":"ok","timestamp":1687775607135,"user_tz":-330,"elapsed":389,"user":{"displayName":"Simandhar Kumar Baid","userId":"16150880934178117180"}},"outputId":"b0d8c342-e095-4034-e642-f15837ffcaa8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 104ms/step\n","[[False]]\n"]}]},{"cell_type":"markdown","source":["#Predicting the Test set results"],"metadata":{"id":"IEp4Ol7wRoTv"}},{"cell_type":"code","source":["y_pred = ann.predict(X_test)\n","y_pred = (y_pred > 0.5)\n","print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvWS2gByRwTz","executionInfo":{"status":"ok","timestamp":1687776012097,"user_tz":-330,"elapsed":650,"user":{"displayName":"Simandhar Kumar Baid","userId":"16150880934178117180"}},"outputId":"60132960-b0fa-4f14-8f9f-0f8455370fe3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["63/63 [==============================] - 0s 2ms/step\n","[[0 0]\n"," [0 1]\n"," [0 0]\n"," ...\n"," [0 0]\n"," [0 0]\n"," [0 0]]\n"]}]},{"cell_type":"markdown","source":["#Making the confusion matrix"],"metadata":{"id":"FhiWbH9JRr8x"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, accuracy_score\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FeeS7_QNSjY1","executionInfo":{"status":"ok","timestamp":1687776026549,"user_tz":-330,"elapsed":405,"user":{"displayName":"Simandhar Kumar Baid","userId":"16150880934178117180"}},"outputId":"ed8da71a-4f9b-4090-a2e4-45c5f5032865"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1526   69]\n"," [ 200  205]]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8655"]},"metadata":{},"execution_count":40}]}]}